#!/bin/bash

################################################################################################ 
	#################### Torque preparation: PBS commands ###################
################################################################################################

### Use the bourne shell
#PBS -S /bin/bash 			

### Run in the queue named default
#PBS -q default				

#### #PBS -d /home/groups/hpcbio_shared/azza/H3A_NextGen_assessment_set3/src-azza

### Specify the number of cpus for your job (nodes and processors)
#PBS -l nodes=1:ppn=23			

### the destination for reporting (defaults to script's directory): Seperate these to get a better sense!
#PBS -o localhost:$HOME/outputs.log.txt
#PBS -e localhost:$HOME/errors.log.txt		

### email me when my job aborts or ends
#PBS -M aeahmed@illinois.edu
#PBS -m abe

# Calculate the number of processors allocated to this run.
NPROCS=`wc -l < $PBS_NODEFILE`

# Calculate the number of nodes allocated.
NNODES=`uniq $PBS_NODEFILE | wc -l`

### Display the job context
echo
echo "Running the job named ($PBS_JOBNAME) identified by ($PBS_JOBID) requested by ($PBS_O_LOGNAME)" > jobinfo.txt
echo "Job is run on host (`hostname`) from the host cluster ($PBS_O_HOST)" >> jobinfo.txt
echo Using ${NPROCS} processors across ${NNODES} nodes >> jobinfo.txt
echo -e  "\n Time is `date`" >> jobinfo.txt

### By default TORQUE launches processes from your home directory, you may need to switch to the working directory; 
printf "\n Note: This job is being executed on the directory `pwd`, even though it was submitted from the directory $PBS_O_WORKDIR "

echo -e "\n\n########################################################################################"
echo -e "#############                Pipeline starts here!              ###############"
echo -e "########################################################################################\n\n"

######### Paths defintions:
reference="/home/groups/hpcbio_shared/azza/H3A_NextGen_assessment_set3/data/genome"
reads="/home/groups/hpcbio_shared/azza/H3A_NextGen_assessment_set3/data/reads"
results="/home/groups/hpcbio_shared/azza/H3A_NextGen_assessment_set3/results"

	# an alternative to having to copy the reference genome (from the gatk bundle in the mirror folder), would have been creating a soft link to it:
	# ln -s /home/mirrors/gatk_bundle/2.8/hg19/ucsc.hg19.fasta reference
	# and now from this point onward, reference is accepted instead of the long path to ucsc.hg19.fasta

######### Some parts were already done, so it would be a good idea to not rerun them!

	######### Reference preparation:

	# The used reference is from the gatk bundle, so no need to do the steps below:
		#module load samtools/1.2
		#samtools faidx $reads/hs_ref_GRCh38.p2_chr1.fa
	# But, you need to index. The indexed file from gatk was generated by fadix, not by bwa's index!

	module load novocraft/3.02
	cd $reference 
	# bwa index is incapable of moving its output around. Do it manually!Generally speaking(moving the files 	from indexing can be tricky with some tools. Better to always go the directory)
	novoindex ucsc.human.nix $reference/ucsc.hg19.fasta
		# the -p parameter is just to name the resulting files human.xx where xx is the various extensions!

	# Also note you are using the complete genome even though you are only interested in certain parts
	# The good news is that this is a one time thing! Your reference can now deal with whatever it is that is 	human!

