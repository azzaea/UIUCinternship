#!/bin/bash

################################################################################################ 
	#################### Torque preparation: PBS commands ###################
################################################################################################

### Use the bourne shell
#PBS -S /bin/bash 			

### Run in the queue named default
#PBS -q default				

#### #PBS -d /home/groups/hpcbio_shared/azza/H3A_NextGen_assessment_set3/src-azza

### Specify the number of cpus for your job (nodes and processors)
#PBS -l nodes=1:ppn=23			

### the destination for reporting (defaults to script's directory): Seperate these to get a better sense!
#PBS -o localhost:$HOME/outputs.log.txt
#PBS -e localhost:$HOME/errors.log.txt		

### email me when my job aborts or ends
#PBS -M aeahmed@illinois.edu
#PBS -m abe

# Calculate the number of processors allocated to this run.
NPROCS=`wc -l < $PBS_NODEFILE`

# Calculate the number of nodes allocated.
NNODES=`uniq $PBS_NODEFILE | wc -l`

### Display the job context
echo
echo "Running the job named ($PBS_JOBNAME) identified by ($PBS_JOBID) requested by ($PBS_O_LOGNAME)" > jobinfo.txt
echo "Job is run on host (`hostname`) from the host cluster ($PBS_O_HOST)" >> jobinfo.txt
echo Using ${NPROCS} processors across ${NNODES} nodes >> jobinfo.txt
echo -e  "\n Time is `date`" >> jobinfo.txt

### By default TORQUE launches processes from your home directory, you may need to switch to the working directory; 
printf "\n Note: This job is being executed on the directory `pwd`, even though it was submitted from the directory $PBS_O_WORKDIR "

echo -e "\n\n########################################################################################"
echo -e "#############                Pipeline starts here!              ###############"
echo -e "########################################################################################\n\n"

######### Paths defintions:
reference="/home/groups/hpcbio_shared/azza/H3A_NextGen_assessment_set3/data/genome"
reads="/home/groups/hpcbio_shared/azza/H3A_NextGen_assessment_set3/data/reads"
results="/home/groups/hpcbio_shared/azza/H3A_NextGen_assessment_set3/results"

	# an alternative to having to copy the reference genome (from the gatk bundle in the mirror folder), would have been creating a soft link to it:
	# ln -s /home/mirrors/gatk_bundle/2.8/hg19/ucsc.hg19.fasta reference
	# and now from this point onward, reference is accepted instead of the long path to ucsc.hg19.fasta

######### Some parts were already done, so it would be a good idea to not rerun them!
if [ $done_parts ]; then

mod	######### Reference preparation:
	gunzip $reference/ucsc*

	# The used reference is from the gatk bundle, so no need to do the steps below:
		#module load samtools/1.2
		#samtools faidx $reads/hs_ref_GRCh38.p2_chr1.fa
	# But, you need to index. The indexed file from gatk was generated by fadix, not by bwa's index!
	module load bwa/0.7.10
	cd $reference 
	# bwa index is incapable of moving its output around. Do it manually!Generally speaking(moving the files 	from indexing can be tricky with some tools. Better to always go the directory)
	bwa index -a bwtsw -p human $reference/ucsc.hg19.fasta
		# the -p parameter is just to name the resulting files human.xx where xx is the various extensions!

	# Also note you are using the complete genome even though you are only interested in certain parts
	# The good news is that this is a one time thing! Your reference can now deal with whatever it is that is 	human!

	######### Quality checking: 
	module load fastqc/0.11.4
	fastqc $reads/H3A_NextGen_assessment.Chr1_50X.set3_read1.fq --outdir=$results
	fastqc $reads/H3A_NextGen_assessment.Chr1_50X.set3_read2.fq --outdir=$results
	# In reality, to see this result, just type: firefox required.read_fastqc.html
	# Reports show data of good quality, except for some kmer content in read1 (Gloria: its near the end, so 	should be ok). Also, the encoding is Sanger, so the reads are neat..
	# A pertinent question is about the read group, Do I accept the info presented on the chromosome here?
	

	######### for the sake of sanity, I created 2 couple read files:
	cp H3A_NextGen_assessment.Chr1_50X.set3_read1.fq read1.fq
	cp H3A_NextGen_assessment.Chr1_50X.set3_read2.fq read2.fq


	######### Alignment: The default settings
	cd $results/p2_alignment/
	mkdir default
	cd default
	
	module load bwa/0.7.15
	module load samtools/1.3.1
	
	START=$(date +%s)
	bwa mem -M -t 12 -R  '@RG\tID:foo\tSM:bar\tLB:library1' $reference/human $reads/read1.fq $reads/read2.fq > a.default.0.sam
	# note that it is the indexed file(s) that was needed in this stage. It has a different name than the 	reference (remember the -p argument), so I need to use its name (human)
	END=$(date +%s)
	[ -s a.default.0.sam ] && echo "Default alignment successeful!" || exit
	alignments=$(samtools view -c a.default.0.sam)
	if [ "$alignments" -eq 0]; then
		echo			
		echo " Unfortunately, I can NOT process the your request with default parameters" 
		echo
		exit
	fi
	samtools view -bS a.default.0.sam > a.default.0.bam
	
	DIFF=$(( $END - $START ))
	
	echo 
	echo "BWA Mem aligned :$alignments: using parameter :default: (*=0=)"  > a.default.0.summary.txt
	echo 
	echo "Execution time is :$DIFF: seconds" >> a.default.0.summary.txt
	echo 
	samtools flagstat a.default.0.bam >> a.default.0.summary.txt  # Generating summary statistics
	
	
	######### Alignment: The combinatorial settings: changing a variable at a time, with the objective of 	having a sense of how things work
	
	
	#echo -e "\n\n########################################################################################"
	#echo -e "#############                CHECKING PARAMETERS                         ###############"
	#echo -e "########################################################################################\n\n"
	
	declare -a parameters=(k r w d c D m W A B O E L U T)
	declare -a min=(3 .5 20 20 300 .1 20 0 1 1 1 1 1 1 10)
	declare -a step=(3 .5 20 20 300 .1 20 3 2 2 2 2 2 3 10)
	declare -a max=(60 4 200 200 10000 1 200 30 20 20 20 20 20 40 80)
	
	cd $results/p2_alignment/
	mkdir ${parameters[@]}
	
	echo The parameters being tested and their ranges are given below:
	echo paramters: ${parameters[@]}, 
	echo minimum  : ${min[@]} 
	echo maximum  : ${max[@]}
	
	pos=0
	while [ $pos -lt ${#parameters[@]} ]; do
	        par=${parameters[pos]}
		cd $results/p2_alignment/$par
	        for i in $(seq ${min[pos]} ${step[pos]} ${max[pos]}); do
			START=$(date +%s)	
			bwa mem -t 12 -$par "$i" -M -R  '@RG\tID:foo\tSM:bar\tLB:library1'  $reference/human $reads/read1.fq $reads/read2.fq  > "a.$par.$i.sam"
			END=$(date +%s)
			DIFF=$(( $END - $START ))
			if [ -s "a.$par.$i.sam" ]; then
				echo "Alignment successeful! with -$par $i" 
			else 
				echo "BWA aligned :0: using default parameter (*=0=)"> "a.$par.$i.summary.txt"
				echo "Execution time is :0: seconds" >> "a.$par.$i.summary.txt"
				continue
			fi
			alignments=$(samtools view -c a.$par.$i.sam)
			if [ "$alignments" -eq 0]; then
				echo			
				echo " Unfortunately, I can NOT process the parameter $par = $i with bwa mem" > "a.$par.$i.summary.txt"
				echo
				echo "BWA aligned :0: using default parameter (*=0=)" > "a.$par.$i.summary.txt"
				echo "Execution time is :0: seconds" >> "a.$par.$i.summary.txt"
				continue
			fi
	
			echo 
			echo "BWA Mem aligned :$alignments: using parameter :$par: =$i" > "a.$par.$i.summary.txt"
			echo 
			echo "Execution time is :$DIFF: seconds" >> "a.$par.$i.summary.txt"
			echo 
			samtools view -bS "a.$par.$i.sam" >"a.$par.$i.bam"
			samtools flagstat a.$par.$i.bam >> "a.$par.$i.summary.txt"
		done
		let pos+=1
	done	

fi

#Some visualization of results should go here!
##############################################################################################################

echo -e "\n\n########################################################################################"
echo -e "#############                Post alignment steps start here!              ###############"
echo -e "########################################################################################\n\n"


######### Post Alignment: Removing mapping artifacts (clipping end of reference, missing mates, reads splitting into adapters...), sorting reads by mapping position, adding read group info if needed and adding cigar information

module load picard-tools/2.4.1
picard=/home/apps/picard-tools/picard-tools-2.4.1/picard.jar

mkdir -p $results/p3_postalignment
cd $results/p3_postalignment

java -Xmx8G -jar $picard FastqToSam FASTQ=$reads/read1.fq FASTQ2=$reads/read2.fq OUTPUT=unmappedbam.sam READ_GROUP_NAME=foo SAMPLE_NAME=bar
# According to the broad's website the inputs need to be queryname sorted first, and this is doen automatically by default by the tool


##### Unpiped processing:
java -Xmx8G -jar $picard SamToFastq I=unmappedbam.sam FASTQ=read1_cleaned_withoutMrkingAdapters.fq SECOND_END_FASTQ=read2_cleaned_withoutMrkingAdapters.fq CLIPPING_ATTRIBUTE=XT  CLIPPING_ACTION=2 NON_PF=true 
# take read identifier, read sequences and base scores to create a sanger fastq file. setting CLIPPING_ATTRIBUTE=XT and CLIPPING_ACTION=2, SamToFastq changes the quality scores of bases marked by XT to two (which is low quality on phred scale). This  effectively removes the adapter portion of sequences from contributing to downstream read alignment and alignment scoring metrics >> the resulting fastq file hass all meta data: read group, alignment, flags and tags in addition to the read query name, read sequences and read base quality scores

module load bwa/0.7.10
bwa mem -M -t 12 $reference/human read1_cleaned_withoutMrkingAdapters.fq read2_cleaned_withoutMrkingAdapters.fq > a.alignedbam_withoutMrkingAdapters.sam
#the alignment file has automatically generated read group info


java -Xmx16G -jar $picard MergeBamAlignment R=$reference/ucsc.hg19.fasta UNMAPPED_BAM=unmappedbam.sam ALIGNED_BAM=a.alignedbam_withoutMrkingAdapters.sam O=cleaned_bam_withoutMrkingAdapters.bam ALIGNER_PROPER_PAIR_FLAGS=false CREATE_INDEX=true ADD_MATE_CIGAR=true CLIP_ADAPTERS=true CLIP_OVERLAPPING_READS=true INCLUDE_SECONDARY_ALIGNMENTS=true MAX_INSERTIONS_OR_DELETIONS=-1 PRIMARY_ALIGNMENT_STRATEGY=BestMapq ATTRIBUTES_TO_RETAIN=XS UNMAP_CONTAMINANT_READS=true TMP_DIR=$results/tmp


####### Summarizing results:
module load samtools/1.3.1

cd $results/p3_postalignment/findings

bam='cleaned_bam_withoutMrkingAdapters.bam'
	mapq=$(samtools view ../$bam | awk '{sum+=$5} END { print sum/NR}')
	echo $bam $mapq >> average_quality.txt

	java -jar $picard CollectAlignmentSummaryMetrics R=$reference/ucsc.hg19.fasta I=../$bam O=overall_summary_$bam.txt
	# produces metrics relating to the overall alignment of reads withing a SAM/BAM. ie it works per bam file
	# The reference file needs a companion dictionary here! it means, use the GATK reference, not the bwa indexed file

	java -jar $picard CollectWgsMetrics I=../$bam O=coverage_metrics_$bam.txt R=$reference/ucsc.hg19.fasta
	# produces metrics relating to reads that pass base and mapping quality filters and coverage (read depth) levels (user defined)
	# to use this tool with WES, you need to give the coordinates of your genomic region!!

	java -jar $picard CollectInsertSizeMetrics I=../$bam O=insert_size_metrics_$bam.txt H=insert_size_histogram_$bam.pdf M=0.5
	# produces metrics for validating library construction including the insert size distribution and read 	orientation of paired end libraries
	# setting the minimum percentage (M=0.5) is convineint for processing a small file


